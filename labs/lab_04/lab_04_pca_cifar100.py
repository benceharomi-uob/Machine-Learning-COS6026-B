# -*- coding: utf-8 -*-
"""lab_04_pca_cifar100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5HZAsFRatZG8jfWoJt8AKeGeKzTHz5U

# CIFAR-100 Dataset

Loading the dataset
"""

from keras.datasets import cifar100

(x_train, y_train), (x_test, y_test) = cifar100.load_data()

"""Printing the shape of the training and testing images"""

print("Traning data shape:", x_train.shape)
print("Testing data shape:", x_test.shape)

"""Printing the shape of the labels


"""

y_train.shape, y_test.shape

"""Printing the total number of classes (the unique numbers from the train labels)"""

import numpy as np

classes = np.unique(y_train)
nClasses = len(classes)

print("Total number of outputs : ", nClasses)
print("Output classes : ", classes)

"""Creating a dictionary with the names of the classes"""

label_dict = {
    0: "apple",
    1: "aquarium_fish",
    2: "baby",
    3: "bear",
    4: "beaver",
    5: "bed",
    6: "bee",
    7: "beetle",
    8: "bicycle",
    9: "bottle",
    10: "bowl",
    11: "boy",
    12: "bridge",
    13: "bus",
    14: "butterfly",
    15: "camel",
    16: "can",
    17: "castle",
    18: "caterpillar",
    19: "cattle",
    20: "chair",
    21: "chimpanzee",
    22: "clock",
    23: "cloud",
    24: "cockroach",
    25: "couch",
    26: "crab",
    27: "crocodile",
    28: "cup",
    29: "dinosaur",
    30: "dolphin",
    31: "elephant",
    32: "flatfish",
    33: "forest",
    34: "fox",
    35: "girl",
    36: "hamster",
    37: "house",
    38: "kangaroo",
    39: "computer_keyboard",
    40: "lamp",
    41: "lawn_mower",
    42: "leopard",
    43: "lion",
    44: "lizard",
    45: "lobster",
    46: "man",
    47: "maple_tree",
    48: "motorcycle",
    49: "mountain",
    50: "mouse",
    51: "mushroom",
    52: "oak_tree",
    53: "orange",
    54: "orchid",
    55: "otter",
    56: "palm_tree",
    57: "pear",
    58: "pickup_truck",
    59: "pine_tree",
    60: "plain",
    61: "plate",
    62: "poppy",
    63: "porcupine",
    64: "possum",
    65: "rabbit",
    66: "raccoon",
    67: "ray",
    68: "road",
    69: "rocket",
    70: "rose",
    71: "sea",
    72: "seal",
    73: "shark",
    74: "shrew",
    75: "skunk",
    76: "skyscraper",
    77: "snail",
    78: "snake",
    79: "spider",
    80: "squirrel",
    81: "streetcar",
    82: "sunflower",
    83: "sweet_pepper",
    84: "table",
    85: "tank",
    86: "telephone",
    87: "television",
    88: "tiger",
    89: "tractor",
    90: "train",
    91: "trout",
    92: "tulip",
    93: "turtle",
    94: "wardrobe",
    95: "whale",
    96: "willow_tree",
    97: "wolf",
    98: "woman",
    99: "worm",
}

"""Displaying the first image in the training and the test data"""

import matplotlib.pyplot as plt

plt.figure(figsize=[5, 5])

# Display the first image in training data
index = 0
plt.subplot(121)
curr_img = np.reshape(x_train[index], (32, 32, 3))
plt.imshow(curr_img)
curr_label = str(label_dict[y_train[index][0]])
print(plt.title("(Label: {})".format(curr_label)))

# Display the first image in testing data
index = 0
plt.subplot(122)
curr_img = np.reshape(x_test[index], (32, 32, 3))
plt.imshow(curr_img)
curr_label = str(label_dict[y_test[index][0]])
print(plt.title("(Label: {})".format(curr_label)))

"""## Visualizing the data

Checking the minimum and the maximum values of the training images
"""

np.min(x_train), np.max(x_train)

"""Normalizing the pixels between 0 and 1 inclusive"""

x_train_normalized = x_train / np.max(x_train)

np.min(x_train_normalized), np.max(x_train_normalized)

x_train_normalized.shape

"""Reshaping the image dimensions from three to one (flattening the images)"""

from functools import reduce

n_cols = reduce((lambda x, y: x * y), x_train_normalized.shape[1:])
print(n_cols)

x_train_flat = x_train_normalized.reshape(-1, n_cols)
x_train_flat.shape

"""Creating a DataFrame that holds the pixel values of the images with their respective labels in a row-column format

The shape should be (50000, 3073) (3072+1 because of the added labels) 
"""

feat_cols = ["pixel{}".format(str(i)) for i in range(x_train_flat.shape[1])]

import pandas as pd

df_cifar = pd.DataFrame(x_train_flat, columns=feat_cols)

df_cifar["label"] = y_train
df_cifar.shape

df_cifar.head()

"""PCA - keeping 3 components, then applying `fit_transform` on the training data"""

from sklearn.decomposition import PCA

pca_cifar = PCA(n_components=3)
principalComponents_cifar = pca_cifar.fit_transform(df_cifar.iloc[:, :-1])

"""Converting from a numpy array to a pandas DataFrame"""

principal_cifar_Df = pd.DataFrame(
    data=principalComponents_cifar,
    columns=["principal component 1", "principal component 2", "principal component 3"],
)
principal_cifar_Df["y"] = y_train

principal_cifar_Df.head()

"""Printing the **variance**"""

print(
    "Explained variation per principal component: {}".format(
        pca_cifar.explained_variance_ratio_
    )
)

"""Visualizing the CIFAR-100 data in two-dimensions using PC1 and PC2"""

import seaborn as sns

plt.figure(figsize=(16, 10))
sns.scatterplot(
    x="principal component 1",
    y="principal component 2",
    hue="y",
    palette=sns.color_palette("hls", 100),
    data=principal_cifar_Df,
    legend="full",
    alpha=0.3,
)

"""Plot for PC2 vs PC3"""

plt.figure(figsize=(16, 10))
sns.scatterplot(
    x="principal component 2",
    y="principal component 3",
    hue="y",
    palette=sns.color_palette("hls", 100),
    data=principal_cifar_Df,
    legend="full",
    alpha=0.3,
)
