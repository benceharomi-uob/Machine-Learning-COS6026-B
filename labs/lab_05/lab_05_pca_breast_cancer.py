# -*- coding: utf-8 -*-
"""lab_05_pca_breast_cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TJr93GqzIQa7HLX5_xHhHEsn8oILycrf

# Breast Cancer Dataset

Loading the dataset
"""

from sklearn.datasets import load_breast_cancer

breast = load_breast_cancer()
breast_data = breast.data

"""Checking the shape of the data"""

breast_data.shape

"""Loading the labels"""

breast_labels = breast.target
breast_labels.shape

"""Reshaping the labels to concatenate with the data"""

import numpy as np

labels = np.reshape(breast_labels,(569,1))
labels.shape

"""Concatenating the data with the label

The shape should be (569, 31) *(30+1 because the label added)*
"""

final_breast_data = np.concatenate([breast_data,labels],axis=1)
final_breast_data.shape

"""Creating a panda DataFrame from the array"""

import pandas as pd

breast_dataset = pd.DataFrame(final_breast_data)
features = breast.feature_names

features

"""Appending the labels to the features"""

features_labels = np.append(features,'label')
breast_dataset.columns = features_labels
breast_dataset.head()

"""Replacing the original labels

0 -> Benign, 1 -> Malignant
"""

breast_dataset['label'].replace(0, 'Benign',inplace=True)
breast_dataset['label'].replace(1, 'Malignant',inplace=True)
breast_dataset.tail()

"""## Visualizing the data"""

x_train = breast_dataset.loc[:, features].values

print(x_train.shape)
np.min(x_train), np.max(x_train)

"""Normalizing the features"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)
x_train_normalized = scaler.transform(x_train)

print(x_train_normalized.shape)
np.min(x_train_normalized), np.max(x_train_normalized)

"""Checking whether the normalized data has a mean of zero and a standard deviation of one"""

print(np.mean(x_train),np.std(x_train))
print(np.mean(x_train_normalized),np.std(x_train_normalized))

"""Converting the normalized features into a DataFrame"""

feat_cols = ['feature{}'.format(str(i)) for i in range(x_train_normalized.shape[1])]

df_breast_normalized = pd.DataFrame(x_train_normalized,columns=feat_cols)

df_breast_normalized['label'] = labels

df_breast_normalized.shape

df_breast_normalized.head()

"""PCA - keeping 3 components, then applying `fit_transform` on the training data"""

from sklearn.decomposition import PCA

pca_breast = PCA(n_components=3)
principalComponents_breast = pca_breast.fit_transform(df_breast_normalized.iloc[:,:-1])

"""Converting from a numpy array to a pandas DataFrame"""

principal_breast_Df = pd.DataFrame(data = principalComponents_breast
             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])
principal_breast_Df['y'] = labels

principal_breast_Df.head()

"""Printing the **variance**"""

print('Explained variation per principal component: {}'.format(pca_breast.explained_variance_ratio_))

"""Visualizing the Breast Cancer data in two-dimensions using seaborn's scatterplot (PC1 vs PC2)"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(16,10))
sns.scatterplot(
    x='principal component 1', y='principal component 2',
    hue="y",
    palette=sns.color_palette('hls', 2),
    data=principal_breast_Df,
    legend='full',
    alpha=0.3
)

"""Seaborn's scatterplot for PC2 vs PC3"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(16,10))
sns.scatterplot(
    x='principal component 2', y='principal component 3',
    hue="y",
    palette=sns.color_palette('hls', 2),
    data=principal_breast_Df,
    legend='full',
    alpha=0.3
)

"""PC1 vs PC2 using pyplot"""

plt.figure()
plt.figure(figsize=(10,10))
plt.xticks(fontsize=12)
plt.yticks(fontsize=14)
plt.xlabel('Principal Component - 1',fontsize=20)
plt.ylabel('Principal Component - 2',fontsize=20)
plt.title("Principal Component Analysis of Breast Cancer Dataset",fontsize=20)
targets = ['Benign', 'Malignant']
colors = ['r', 'g']
for target, color in zip(targets,colors):
    indicesToKeep = breast_dataset['label'] == target
    plt.scatter(principal_breast_Df.loc[indicesToKeep, 'principal component 1']
               , principal_breast_Df.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)

plt.legend(targets,prop={'size': 15})

"""PC2 vs PC3 using pyplot"""

plt.figure()
plt.figure(figsize=(10,10))
plt.xticks(fontsize=12)
plt.yticks(fontsize=14)
plt.xlabel('Principal Component - 2',fontsize=20)
plt.ylabel('Principal Component - 3',fontsize=20)
plt.title("Principal Component Analysis of Breast Cancer Dataset",fontsize=20)
targets = ['Benign', 'Malignant']
colors = ['r', 'g']
for target, color in zip(targets,colors):
    indicesToKeep = breast_dataset['label'] == target
    plt.scatter(principal_breast_Df.loc[indicesToKeep, 'principal component 2']
               , principal_breast_Df.loc[indicesToKeep, 'principal component 3'], c = color, s = 50)

plt.legend(targets,prop={'size': 15})

"""## Deep learning"""

x = breast_dataset.loc[:, features].values
x.shape

y = labels
y.shape

import math

train_data_len = math.floor(len(x)*0.8)
train_data_len

x_train = x[:train_data_len]
x_test = x[train_data_len:]
print(x_train.shape)
print(x_test.shape)

y_train = y[:train_data_len]
y_test = y[train_data_len:]

np.min(x_train), np.max(x_train)

scaler = StandardScaler()
scaler.fit(x_train)

x_train_normalized = scaler.transform(x_train)

pca = PCA(0.9)

pca.fit(x_train_normalized)

pca.n_components_

x_test_normalized = scaler.transform(x_test)

train_img_pca = pca.transform(x_train_normalized)
test_img_pca = pca.transform(x_test_normalized)

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from keras.optimizers import RMSprop

y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

batch_size = 128
num_classes = 2
num_components = pca.n_components_
epochs = 20

model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=(num_components,)))
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history = model.fit(train_img_pca, y_train,batch_size=batch_size,epochs=epochs,verbose=1,
                    validation_data=(test_img_pca, y_test))

batch_size = 128
num_classes = 2
num_components = 30
epochs = 20

model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=(num_components,)))
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history = model.fit(x_train_normalized, y_train,batch_size=batch_size,epochs=epochs,verbose=1,
                    validation_data=(x_test_normalized, y_test))