# -*- coding: utf-8 -*-
"""ML_Assignment_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bSntvwAqyHll6eoqhzTgdGk3Jrw_V8aC

# Diabetic Retinopathy with Machine Learning

## Loading the dataset
"""

url = '../data/17006903.csv'

names = ['quality', 'retinal_abnormality']
names.extend(['feat1_{}'.format(str(i)) for i in range(6)])
names.extend(['feat2_{}'.format(str(i)) for i in range(8)])
names.extend(['dist_of_macula_and_optic_disc', 'diameter_of_optic_disc', 'am_fm_classification', 'dr'])
len(names)

import pandas as pd

dataset = pd.read_csv(url)
dataset.columns = names
dataset.head()

dataset.shape

"""## Preprocessing

Looking for missing values:
"""

dataset.isnull().values.any()

"""There is no missing value in the dataset

Checking if are there any columns which only contain 1 value:
"""

dataset.nunique()

"""All the columns have at least 2 type of values, thus nothing to remove.

Looking for duplicate rows
"""

dups = dataset.duplicated()
print(dups.any())
print(dataset[dups].shape)
dataset[dups]

"""There are 5 duplicated rows which needs to be removed.

Removing the duplicated values, and checking if all of them deleted succesfully
"""

dataset.drop_duplicates(inplace=True)
dataset.duplicated().any()

"""Count the rows where the image's quality is bad (quality != 1)"""

dataset[dataset.quality != 1].shape

"""4 rows found, removing them:"""

dataset = dataset[dataset.quality == 1]
dataset.shape

"""After all the records removed where the image's quality was bad the `quality` column become unnecessary. """

dataset.drop(['quality'], axis=1, inplace=True)
dataset.shape

"""Checking how balanced the dataset is

Counting the positives and negatives
"""

dataset[dataset.dr == 1].shape

dataset[dataset.dr == 0].shape

"""## Training"""

df = dataset
df

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

def normalize_datasets(train_df, test_df):
  scaler = MinMaxScaler()

  ## Filtering out the boolean columns
  col_names =  names[2:-2]

  train_df_norm = train_df.copy()
  features = train_df_norm[col_names]

  scaler = scaler.fit(features.values)
  features = scaler.transform(features.values)
  train_df_norm[col_names] = features

  test_df_norm = test_df.copy()
  features = test_df_norm[col_names]
  features = scaler.transform(features.values)
  test_df_norm[col_names] = features

  return train_df_norm, test_df_norm

print("Defined the normalize_datasets function.")

import datetime
import tensorflow
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, DenseFeatures
from keras.optimizers import Adam
from keras.losses import BinaryCrossentropy, Reduction

def create_model(learning_rate, metrics, feature_columns, regularization=False):                         
  model = Sequential()
  
  model.add(DenseFeatures(feature_columns))
  model.add(Dense(units=100, activation='relu', name='Hidden1'))
  if(regularization):
    model.add(Dropout(rate=0.05, name='Hidden2'))
  model.add(Dense(units=100, activation='relu', name='Hidden3'))
  model.add(Dense(units=1, activation='sigmoid', name='Output'))
    
  optimizer = Adam(lr=learning_rate)
  loss = BinaryCrossentropy(reduction=Reduction.NONE)
  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

  return model

  print("Defined the create_model function.")

import numpy as np

def split_features_and_label(df):
  features = {name:np.array(value) for name, value in df.items()}
  label = np.array(features.pop(label_name))
  return features, label 

def train_model(model, train_df, test_df, num_of_epochs, label_name, batch_size=None):
  train_features, train_label = split_features_and_label(train_df)
  test_features, test_label = split_features_and_label(test_df)

  history = model.fit(x=train_features, y=train_label, batch_size=batch_size, epochs=num_of_epochs, validation_data=(test_features, test_label), shuffle=True, verbose=1) 
  
  return  pd.DataFrame(history.history)

print("Defined the split_features_and_label and the train_model functions.")

def make_plot(data_array, legend_array, plot_title, x_label, y_label):
  plt.figure(figsize=(10, 5))
  for item in data_array:
    plt.plot(item)
  plt.title(label=plot_title)
  plt.xlabel(xlabel=x_label)
  plt.ylabel(ylabel=y_label)
  plt.ylim((0, 1))
  plt.legend(legend_array, loc='upper left');

print("Defined the make_plot function.")

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def plot_confusion_matrix(cnf_matrix):
  class_names = [0,1]
  fig,ax = plt.subplots()
  tick_marks = np.arange(len(class_names))
  plt.xticks(tick_marks,class_names)
  plt.yticks(tick_marks,class_names)

  sns.heatmap(pd.DataFrame(cnf_matrix),annot=True,cmap="Blues",fmt="d",cbar=False)
  ax.xaxis.set_label_position('top')
  plt.tight_layout()
  plt.ylabel('Actual label')
  plt.xlabel('Predicted label');
  plt.show()

print("Defined the plot_confusion_matrix function.")

def get_stats(model, test_df_norm, accuracy_array, fscore_array, precision_array, sensitivity_array, specificity_array, cnf_dict):
  x_test, y_test = split_features_and_label(df=test_df_norm)
  current_accuracy = model.evaluate(x_test, y_test)[1]
  accuracy_history_array.append(current_accuracy)

  predictions = model.predict(x_test)
  bin_predictions = tf.round(predictions).numpy().flatten()
  current_cnf = confusion_matrix(y_test, bin_predictions)
  cnf_history_array.append(current_cnf)

  tn = current_cnf[0][0]
  fp = current_cnf[0][1]
  fn = current_cnf[1][0]
  tp = current_cnf[1][1]
  cnf_dict['tn'] += tn
  cnf_dict['fp'] += fp
  cnf_dict['fn'] += fn
  cnf_dict['tp'] += tp

  accuracy = (tp + tn) / (tp + fp + tn + fn)
  fscore = (2 * tp) / ((2 * tp) + fn + fp)
  precision = tp / (tp + fp)
  sensitivity = tp / (tp + fn)
  specificity = tn / (tn + fp)
  accuracy_array.append(accuracy)
  fscore_array.append(fscore)
  precision_array.append(precision)
  sensitivity_array.append(sensitivity)
  specificity_array.append(specificity)

def print_stats(accuracy_array, fscore_array, precision_array, sensitivity_array, specificity_array, cnf_dict):
  n_accuracy = np.array(accuracy_array)
  n_fscore = np.array(fscore_array)
  n_precision = np.array(precision_array)
  n_sensitivity = np.array(sensitivity_array)
  n_specificity = np.array(specificity_array)


  accuracy = np.mean(n_accuracy)
  fscore = np.mean(n_fscore)
  precision = np.mean(n_precision)
  sensitivity = np.mean(n_sensitivity)
  specificity = np.mean(n_specificity)

  accuracy_percentage = accuracy * 100
  fscore_percentage = fscore * 100
  precision_percentage = precision * 100
  sensitivity_percentage = sensitivity * 100
  specificity_percentage = specificity * 100

  print('accuracy:\t{0:0.2f}%'.format(accuracy_percentage))
  print('f-score:\t{0:0.2f}%'.format(fscore_percentage))
  print('precision:\t{0:0.2f}%'.format(precision_percentage))
  print('sensitivity:\t{0:0.2f}%'.format(sensitivity_percentage))
  print('specificity:\t{0:0.2f}%'.format(specificity_percentage))
  cnf_matrix = [[cnf_dict['tn'], cnf_dict['fp']],
                [cnf_dict['fn'], cnf_dict['tp']]]
  plot_confusion_matrix(cnf_matrix)

import tensorflow as tf
from tensorflow.feature_column import numeric_column, categorical_column_with_vocabulary_list, indicator_column

feature_columns = []

numeric_columns_to_add = ['feat1_0', 'feat1_1', 'feat1_2', 'feat1_3', 'feat1_4',
                          'feat1_5', 'feat2_0', 'feat2_1', 'feat2_2', 'feat2_3',
                          'feat2_4', 'feat2_5', 'feat2_6', 'feat2_7',
                          'dist_of_macula_and_optic_disc',
                          'diameter_of_optic_disc']
# numeric columns
for header in numeric_columns_to_add:
  feature_columns.append(numeric_column(header))

# indicator columns
am_fm_classification = categorical_column_with_vocabulary_list(key='am_fm_classification', vocabulary_list=[0, 1])
am_fm_classification_one_hot = indicator_column(categorical_column=am_fm_classification)
feature_columns.append(am_fm_classification_one_hot)

retinal_abnormality = categorical_column_with_vocabulary_list(key='retinal_abnormality', vocabulary_list=[0, 1])
retinal_abnormality_one_hot = indicator_column(categorical_column=retinal_abnormality)
feature_columns.append(retinal_abnormality_one_hot)

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as pyplot

learning_rate = 0.01
num_of_epochs = 100
batch_size = 32
label_name = 'dr'
metrics = ['accuracy']

# initializing the history arrays
accuracy_history_array = []
cnf_history_array = []

history_array = []
accuracy_array = []
fscore_array = []
precision_array = []
sensitivity_array = []
specificity_array = []
cnf_dict = {}
cnf_dict['tn'] = 0
cnf_dict['fp'] = 0
cnf_dict['fn'] = 0
cnf_dict['tp'] = 0

history_reg_array = []
accuracy_reg_array = []
fscore_reg_array = []
precision_reg_array = []
sensitivity_reg_array = []
specificity_reg_array = []
cnf_reg_dict = {}
cnf_reg_dict['tn'] = 0
cnf_reg_dict['fp'] = 0
cnf_reg_dict['fn'] = 0
cnf_reg_dict['tp'] = 0

num_of_iterations = 10

# randomizing the values, splitting training/test dataset and trainig iterating num_of_iteartions times
for _ in range(num_of_iterations):
  # splitting and normalizing the dataset
  train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)
  train_df_norm, test_df_norm = normalize_datasets(train_df=train_df, test_df=test_df)

  #creating the model
  model = create_model(learning_rate=learning_rate, metrics=metrics, feature_columns=feature_columns, regularization=False)
  model_reg = create_model(learning_rate=learning_rate, metrics=metrics, feature_columns=feature_columns, regularization=True)
  # training the model
  history = train_model(model=model, train_df=train_df_norm, test_df=test_df_norm, num_of_epochs=num_of_epochs, label_name=label_name, batch_size=batch_size)
  history_reg = train_model(model=model_reg, train_df=train_df_norm, test_df=test_df_norm, num_of_epochs=num_of_epochs, label_name=label_name, batch_size=batch_size)
  
  # saving the history
  history_array.append(history)
  history_reg_array.append(history_reg)

  get_stats(
      model=model,
      test_df_norm=test_df_norm,
      accuracy_array=accuracy_array,
      fscore_array=fscore_array,
      precision_array=precision_array,
      sensitivity_array=sensitivity_array,
      specificity_array=specificity_array,
      cnf_dict=cnf_dict
      )
  get_stats(
      model=model_reg, 
      test_df_norm=test_df_norm,
      accuracy_array=accuracy_reg_array,
      fscore_array=fscore_reg_array,
      precision_array=precision_reg_array,
      sensitivity_array=sensitivity_reg_array,
      specificity_array=specificity_reg_array,
      cnf_dict=cnf_reg_dict
      )

n_accuracy_history = np.array(accuracy_history_array)
mean_accuracy = n_accuracy_history.mean()
print('Mean accuracy: {}'.format(mean_accuracy))

print_stats(
    accuracy_array=accuracy_array,
    fscore_array=fscore_array,
    precision_array=precision_array,
    sensitivity_array=sensitivity_array,
    specificity_array=specificity_array,
    cnf_dict=cnf_dict
    )

print_stats(
    accuracy_array=accuracy_reg_array,
    fscore_array=fscore_reg_array,
    precision_array=precision_reg_array,
    sensitivity_array=sensitivity_reg_array,
    specificity_array=specificity_reg_array,
    cnf_dict=cnf_reg_dict
    )